---
layout: post
title: Semester 1 | Weeks 11-13
---

Convolutional neural networks slide small matrices called a kernel or filter over the input data (which at this point should already be quantified). The kernel slides over subsections of the input data, performing multiplication between the kernel and the input values. The result is a new matrix, or a feature map, which represents important features from the input data. Kernels can be modified to extract different features. For example, in the context of images, some kernels can be used for image smoothing or edge detection. Convolutional layers identify local patterns such as corners and edges, and then use these patterns to construct more complex features, like shapes and textures. 

The dimensionality of convolution is determined by the input data. Since our input data is a matrix with rows and columns, we will be performing two dimensional convolution. When building our model, we need to consider a variety of hyperparameters; the size/depth of the model, the size of the kernel, stride, padding, and pooling. Considering depth, a deeper network will be able to learn more features, but at the risk of overfitting. When looking at kernels, a smaller kernel will be able to capture local features, while larger kernels can capture global features. Stride determines how much the kernel moves between each convolutional operation. A larger stride can reduce the size of the output feature map, but at the expense of feature information. Padding adds additional pixels around the edges of the matrix, which can impact the size of the output feature map. Finally, pooling layers reduce the dimension of the feature map by aggregating the feature values, which impacts the size and quality of the features produced by the model. 

Building the model can be complicated, and as we saw from above, a multitude of features needs to be considered. I decided to build the simplest 2D convolutional model to test for errors in my data preprocessing and formatting. In pytorch, we can define this model as a single convolutional layer with a 3x3 kernel size, followed by a max pooling layer, and ending with a single fully connected layer. 

Rather than testing the model on the entire dataset, I chose to evaluate its performance on a single example consisting of a matrix and its corresponding junction usage ratio. This allowed me to gain a better understanding of how the model works on a small scale and identify any potential issues in my data before scaling up to the full dataset. I set the training loop to commence over ten epochs, which means that the model will be trained on the single example ten times. Even though we only have one example, training the model for multiple epochs will help it improve its performance by adjusting its weights based on the error it generates when making predictions. 

After troubleshooting the training loop for our model, we finally get a result after training for ten epochs. This is an encouraging sign, as it suggests that our model is able to learn from a single example and improve its performance over time. We can start to scale up our training set to include more data, and eventually evaluate the model's performance on the larger dataset and begin experimenting with different model parameters and hyperparameters to optimize its performance.

Overall, I am happy with the progress made on the project. I started the semester with minimal artificial intelligence/machine learning knowledge, and eventually built a simple but working model. A lot of time was spent refreshing and building my knowledge of genomics. Additionally, I built on my knowledge of machine learning, understanding the importance of data exploration and augmentation. In the next semester, I am excited to further the development of my model, and finally test it on new, unseen datasets. 

Sources: 
https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1
https://www.tensorflow.org/tutorials/images/cnn


